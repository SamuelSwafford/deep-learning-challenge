{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90881,"status":"ok","timestamp":1714181512653,"user":{"displayName":"Samuel Swafford","userId":"16821925915771810862"},"user_tz":300},"id":"xS02hgVv3Zon","outputId":"274040c5-110c-4e97-f9f1-224a304a63c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n","\n","Best layer 1 units: 512\n","Best layer 2 units: 16\n","Best learning rate: 0.001\n","\n","Epoch 1/50\n","850/858 [============================>.] - ETA: 0s - loss: 0.5637 - accuracy: 0.7215\n","Epoch 1: val_accuracy improved from -inf to 0.72420, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 3s 2ms/step - loss: 0.5636 - accuracy: 0.7217 - val_loss: 0.5607 - val_accuracy: 0.7242\n","Epoch 2/50\n"," 83/858 [=>............................] - ETA: 1s - loss: 0.5678 - accuracy: 0.7157"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["856/858 [============================>.] - ETA: 0s - loss: 0.5528 - accuracy: 0.7289\n","Epoch 2: val_accuracy did not improve from 0.72420\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5527 - accuracy: 0.7290 - val_loss: 0.5597 - val_accuracy: 0.7233\n","Epoch 3/50\n","836/858 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.7297\n","Epoch 3: val_accuracy improved from 0.72420 to 0.72580, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5500 - accuracy: 0.7295 - val_loss: 0.5569 - val_accuracy: 0.7258\n","Epoch 4/50\n","837/858 [============================>.] - ETA: 0s - loss: 0.5491 - accuracy: 0.7316\n","Epoch 4: val_accuracy did not improve from 0.72580\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.7320 - val_loss: 0.5552 - val_accuracy: 0.7235\n","Epoch 5/50\n","837/858 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.7317\n","Epoch 5: val_accuracy improved from 0.72580 to 0.72755, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7313 - val_loss: 0.5542 - val_accuracy: 0.7276\n","Epoch 6/50\n","843/858 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.7338\n","Epoch 6: val_accuracy improved from 0.72755 to 0.72915, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7335 - val_loss: 0.5553 - val_accuracy: 0.7292\n","Epoch 7/50\n","845/858 [============================>.] - ETA: 0s - loss: 0.5446 - accuracy: 0.7341\n","Epoch 7: val_accuracy did not improve from 0.72915\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7335 - val_loss: 0.5545 - val_accuracy: 0.7278\n","Epoch 8/50\n","838/858 [============================>.] - ETA: 0s - loss: 0.5445 - accuracy: 0.7329\n","Epoch 8: val_accuracy did not improve from 0.72915\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7329 - val_loss: 0.5548 - val_accuracy: 0.7292\n","Epoch 9/50\n","856/858 [============================>.] - ETA: 0s - loss: 0.5435 - accuracy: 0.7344\n","Epoch 9: val_accuracy improved from 0.72915 to 0.72945, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7344 - val_loss: 0.5556 - val_accuracy: 0.7294\n","Epoch 10/50\n","847/858 [============================>.] - ETA: 0s - loss: 0.5432 - accuracy: 0.7348\n","Epoch 10: val_accuracy did not improve from 0.72945\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7345 - val_loss: 0.5540 - val_accuracy: 0.7273\n","Epoch 11/50\n","858/858 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.7337\n","Epoch 11: val_accuracy did not improve from 0.72945\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7337 - val_loss: 0.5550 - val_accuracy: 0.7292\n","Epoch 12/50\n","846/858 [============================>.] - ETA: 0s - loss: 0.5432 - accuracy: 0.7335\n","Epoch 12: val_accuracy improved from 0.72945 to 0.73032, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7338 - val_loss: 0.5538 - val_accuracy: 0.7303\n","Epoch 13/50\n","857/858 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.7352\n","Epoch 13: val_accuracy did not improve from 0.73032\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7352 - val_loss: 0.5516 - val_accuracy: 0.7299\n","Epoch 14/50\n","852/858 [============================>.] - ETA: 0s - loss: 0.5416 - accuracy: 0.7351\n","Epoch 14: val_accuracy improved from 0.73032 to 0.73061, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7355 - val_loss: 0.5529 - val_accuracy: 0.7306\n","Epoch 15/50\n","847/858 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7351\n","Epoch 15: val_accuracy improved from 0.73061 to 0.73192, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.7352 - val_loss: 0.5535 - val_accuracy: 0.7319\n","Epoch 16/50\n","831/858 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.7353\n","Epoch 16: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.7356 - val_loss: 0.5524 - val_accuracy: 0.7293\n","Epoch 17/50\n","834/858 [============================>.] - ETA: 0s - loss: 0.5403 - accuracy: 0.7373\n","Epoch 17: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.7371 - val_loss: 0.5504 - val_accuracy: 0.7319\n","Epoch 18/50\n","838/858 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.7352\n","Epoch 18: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7355 - val_loss: 0.5556 - val_accuracy: 0.7302\n","Epoch 19/50\n","828/858 [===========================>..] - ETA: 0s - loss: 0.5410 - accuracy: 0.7357\n","Epoch 19: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7361 - val_loss: 0.5513 - val_accuracy: 0.7283\n","Epoch 20/50\n","841/858 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.7375\n","Epoch 20: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7371 - val_loss: 0.5553 - val_accuracy: 0.7313\n","Epoch 21/50\n","847/858 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7371\n","Epoch 21: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7369 - val_loss: 0.5538 - val_accuracy: 0.7283\n","Epoch 22/50\n","832/858 [============================>.] - ETA: 0s - loss: 0.5394 - accuracy: 0.7367\n","Epoch 22: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7370 - val_loss: 0.5532 - val_accuracy: 0.7292\n","Epoch 23/50\n","853/858 [============================>.] - ETA: 0s - loss: 0.5386 - accuracy: 0.7372\n","Epoch 23: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7371 - val_loss: 0.5529 - val_accuracy: 0.7292\n","Epoch 24/50\n","847/858 [============================>.] - ETA: 0s - loss: 0.5388 - accuracy: 0.7366\n","Epoch 24: val_accuracy did not improve from 0.73192\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7367 - val_loss: 0.5561 - val_accuracy: 0.7278\n","Epoch 25/50\n","858/858 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.7365\n","Epoch 25: val_accuracy improved from 0.73192 to 0.73251, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7365 - val_loss: 0.5542 - val_accuracy: 0.7325\n","Epoch 26/50\n","844/858 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.7367\n","Epoch 26: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7371 - val_loss: 0.5538 - val_accuracy: 0.7290\n","Epoch 27/50\n","837/858 [============================>.] - ETA: 0s - loss: 0.5377 - accuracy: 0.7375\n","Epoch 27: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7369 - val_loss: 0.5538 - val_accuracy: 0.7293\n","Epoch 28/50\n","847/858 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.7385\n","Epoch 28: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.7380 - val_loss: 0.5531 - val_accuracy: 0.7305\n","Epoch 29/50\n","857/858 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.7375\n","Epoch 29: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7375 - val_loss: 0.5556 - val_accuracy: 0.7281\n","Epoch 30/50\n","831/858 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.7370\n","Epoch 30: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7367 - val_loss: 0.5536 - val_accuracy: 0.7299\n","Epoch 31/50\n","845/858 [============================>.] - ETA: 0s - loss: 0.5377 - accuracy: 0.7369\n","Epoch 31: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7372 - val_loss: 0.5562 - val_accuracy: 0.7292\n","Epoch 32/50\n","853/858 [============================>.] - ETA: 0s - loss: 0.5372 - accuracy: 0.7377\n","Epoch 32: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7377 - val_loss: 0.5538 - val_accuracy: 0.7310\n","Epoch 33/50\n","852/858 [============================>.] - ETA: 0s - loss: 0.5371 - accuracy: 0.7380\n","Epoch 33: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7382 - val_loss: 0.5552 - val_accuracy: 0.7324\n","Epoch 34/50\n","835/858 [============================>.] - ETA: 0s - loss: 0.5358 - accuracy: 0.7385\n","Epoch 34: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7380 - val_loss: 0.5549 - val_accuracy: 0.7299\n","Epoch 35/50\n","834/858 [============================>.] - ETA: 0s - loss: 0.5364 - accuracy: 0.7380\n","Epoch 35: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7380 - val_loss: 0.5554 - val_accuracy: 0.7305\n","Epoch 36/50\n","857/858 [============================>.] - ETA: 0s - loss: 0.5368 - accuracy: 0.7378\n","Epoch 36: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7379 - val_loss: 0.5538 - val_accuracy: 0.7312\n","Epoch 37/50\n","852/858 [============================>.] - ETA: 0s - loss: 0.5362 - accuracy: 0.7377\n","Epoch 37: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7376 - val_loss: 0.5551 - val_accuracy: 0.7322\n","Epoch 38/50\n","830/858 [============================>.] - ETA: 0s - loss: 0.5372 - accuracy: 0.7386\n","Epoch 38: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7389 - val_loss: 0.5555 - val_accuracy: 0.7310\n","Epoch 39/50\n","858/858 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.7384\n","Epoch 39: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7384 - val_loss: 0.5552 - val_accuracy: 0.7303\n","Epoch 40/50\n","846/858 [============================>.] - ETA: 0s - loss: 0.5362 - accuracy: 0.7383\n","Epoch 40: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7386 - val_loss: 0.5541 - val_accuracy: 0.7312\n","Epoch 41/50\n","834/858 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.7394\n","Epoch 41: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7392 - val_loss: 0.5566 - val_accuracy: 0.7316\n","Epoch 42/50\n","830/858 [============================>.] - ETA: 0s - loss: 0.5360 - accuracy: 0.7384\n","Epoch 42: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7383 - val_loss: 0.5556 - val_accuracy: 0.7300\n","Epoch 43/50\n","841/858 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.7391\n","Epoch 43: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7389 - val_loss: 0.5548 - val_accuracy: 0.7316\n","Epoch 44/50\n","852/858 [============================>.] - ETA: 0s - loss: 0.5357 - accuracy: 0.7391\n","Epoch 44: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7389 - val_loss: 0.5553 - val_accuracy: 0.7303\n","Epoch 45/50\n","845/858 [============================>.] - ETA: 0s - loss: 0.5361 - accuracy: 0.7383\n","Epoch 45: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7390 - val_loss: 0.5597 - val_accuracy: 0.7299\n","Epoch 46/50\n","831/858 [============================>.] - ETA: 0s - loss: 0.5368 - accuracy: 0.7386\n","Epoch 46: val_accuracy did not improve from 0.73251\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7386 - val_loss: 0.5572 - val_accuracy: 0.7318\n","Epoch 47/50\n","845/858 [============================>.] - ETA: 0s - loss: 0.5362 - accuracy: 0.7389\n","Epoch 47: val_accuracy improved from 0.73251 to 0.73265, saving model to AlphabetSoupCharity_Optimized.h5\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7391 - val_loss: 0.5547 - val_accuracy: 0.7327\n","Epoch 48/50\n","847/858 [============================>.] - ETA: 0s - loss: 0.5349 - accuracy: 0.7382\n","Epoch 48: val_accuracy did not improve from 0.73265\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7379 - val_loss: 0.5561 - val_accuracy: 0.7315\n","Epoch 49/50\n","854/858 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.7383\n","Epoch 49: val_accuracy did not improve from 0.73265\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7382 - val_loss: 0.5554 - val_accuracy: 0.7309\n","Epoch 50/50\n","857/858 [============================>.] - ETA: 0s - loss: 0.5345 - accuracy: 0.7384\n","Epoch 50: val_accuracy did not improve from 0.73265\n","858/858 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7385 - val_loss: 0.5574 - val_accuracy: 0.7302\n","215/215 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7327\n","Loss: 0.5547264218330383, Accuracy: 0.7326530814170837\n"]}],"source":["\n","# Import our dependencies\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import keras_tuner as kt\n","\n","# Import and read the charity_data.csv.\n","application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n","application_df = application_df.drop(columns=['EIN', 'NAME'])\n","\n","# Binning APPLICATION_TYPE and CLASSIFICATION with a specified cutoff\n","application_types_to_replace = application_df['APPLICATION_TYPE'].value_counts()[application_df['APPLICATION_TYPE'].value_counts() < 500].index.tolist()\n","classifications_to_replace = application_df['CLASSIFICATION'].value_counts()[application_df['CLASSIFICATION'].value_counts() < 100].index.tolist()\n","\n","for app in application_types_to_replace:\n","    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app, \"Other\")\n","for cls in classifications_to_replace:\n","    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls, \"Other\")\n","\n","# Convert categorical data to numeric with `pd.get_dummies`\n","application_df_encoded = pd.get_dummies(application_df)\n","y = application_df_encoded['IS_SUCCESSFUL'].values\n","X = application_df_encoded.drop(['IS_SUCCESSFUL'], axis=1).values\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scaling\n","scaler = StandardScaler()\n","X_scaler = scaler.fit(X_train)\n","X_train_scaled = X_scaler.transform(X_train)\n","X_test_scaled = X_scaler.transform(X_test)\n","\n","\"\"\"## Hyperparameter Tuning\"\"\"\n","\n","# Define the model-building function\n","def build_model(hp):\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Dense(\n","            units=hp.Int('units_layer1', min_value=32, max_value=512, step=32),\n","            activation='relu',\n","            input_dim=X_train_scaled.shape[1]\n","        ),\n","        tf.keras.layers.Dense(\n","            units=hp.Int('units_layer2', min_value=16, max_value=256, step=32),\n","            activation='relu'\n","        ),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","\n","    hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model\n","\n","# Initialize the tuner and perform hyperparameter tuning\n","tuner = kt.Hyperband(build_model,\n","                     objective='val_accuracy',\n","                     max_epochs=10,\n","                     factor=3,\n","                     directory='my_dir',\n","                     project_name='intro_to_kt')\n","\n","stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","\n","tuner.search(X_train_scaled, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n","\n","# Get the optimal hyperparameters\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(f\"\"\"\n","Best layer 1 units: {best_hps.get('units_layer1')}\n","Best layer 2 units: {best_hps.get('units_layer2')}\n","Best learning rate: {best_hps.get('learning_rate')}\n","\"\"\")\n","\n","# ModelCheckpoint to save the best model during training\n","checkpoint_filepath = 'AlphabetSoupCharity_Optimized.h5'\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    verbose=1)\n","\n","# Train the model\n","model = tuner.hypermodel.build(best_hps)\n","model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[model_checkpoint_callback])\n","\n","\n","\n","# Load the saved model and recompile it\n","model = tf.keras.models.load_model('AlphabetSoupCharity_Optimized.h5')\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test_scaled, y_test)\n","print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thMtXn_3DVjz"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
